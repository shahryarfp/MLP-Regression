# -*- coding: utf-8 -*-
"""DL_HW2_q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VXmh6WnLfV4DGpPkQFdi9IlPzUDmwJG6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
# import random
# from skimage import color
# # from sklearn.metrics import confusion_matrix
# from sklearn import metrics
# import seaborn as sns
my_file = pd.read_csv('MLP-Regression.csv')

#displaying first 3 datas
my_file.head(2)

my_file.info()

"""### Pre Processing"""

#from the info method it is obvious that we have 13 Numerical and 5 Categorical column
#converting categorical to numerical
my_file.date = my_file.date.astype("category").cat.codes
my_file.street = my_file.street.astype("category").cat.codes
my_file.city = my_file.city.astype("category").cat.codes
my_file.statezip = my_file.statezip.astype("category").cat.codes
my_file.country = my_file.country.astype("category").cat.codes
my_file.head(5)

#normalizing
normalized_file = (my_file-my_file.min() + 1)/(my_file.max()-my_file.min() + 1)
normalized_file.head(2)

"""### Deviding Dataset"""

x_training = normalized_file.sample(frac=0.65)
normalized_file = normalized_file.drop(x_training.index)
x_validation = normalized_file.sample(frac=15/35)
x_test = normalized_file.drop(x_validation.index)
# x_test = normalized_file.sample(frac=0.20)

y_training = x_training['price']
x_training.drop('price',inplace=True,axis=1)
y_validation = x_validation['price']
x_validation.drop('price',inplace=True,axis=1)
y_test = x_test['price']
x_test.drop('price',inplace=True,axis=1)

x_training  = x_training.values
y_training  = y_training.values
x_validation  = x_validation.values
y_validation  = y_validation.values
x_test  = x_test.values
y_test  = y_test.values

x_test.shape

y_test.shape

"""### Creating Model"""

from keras import layers
model = tf.keras.Sequential()

activation_func = 'linear'
# activation_func = 'relu'

#layer1
model.add(layers.Dense(25, activation=activation_func ,input_shape=(17,)))
model.add(layers.Dropout(0.2))

#layer 2
model.add(layers.Dense(20, activation=activation_func))
model.add(layers.Dropout(0.2))

#last layer
model.add(layers.Dense(1,activation=activation_func))

# model.summary()

"""#### Compiling the Model"""

# loss_func = 'categorical_crossentropy'
# loss_func = 'mean_squared_error'
# loss_func = 'mean_absolute_error'
# loss_func = 'mse'
loss_func = 'mae'

optimizer_func = 'adam'
# optimizer_func = tf.keras.optimizers.SGD(learning_rate = 0.1)
# optimizer_func = tf.keras.optimizers.Adagrad(learning_rate = 0.1)

model.compile(loss=loss_func,
              optimizer=optimizer_func,
              metrics=['mse','mae'])

"""#### Training the Model"""

import datetime
start = datetime.datetime.now()
trainedModel = model.fit(x_training, y_training, batch_size=128, epochs=35, validation_data = (x_validation,y_validation))
end = datetime.datetime.now()

print('Training Duration: ', end-start)

"""#### Evaluating the Model"""

history = trainedModel.history
mae = history['mae']
val_mae = history['val_mae']
mse = history['mse']
val_mse = history['val_mse']

plt.xlabel('Epochs')
plt.ylabel('Cost')
# plt.ylim(0, np.amax(mae)/3)
plt.plot(mae)
plt.plot(val_mae)
plt.legend(['mae','val_mae'])
plt.figure()

plt.xlabel('Epochs')
plt.ylabel('Cost')
# plt.ylim(0, np.amax(mse)/3)
plt.plot(mse)
plt.plot(val_mse)
plt.legend(['mse','val_mse'])

#plotting predicted and real
y_pred = model.predict(x_test)
plt.xlabel('y_test')
plt.ylabel('y_predicted')
plt.xlim(0, np.amax(y_pred))
plt.ylim(0, np.amax(y_pred))
plt.scatter(y_test, y_pred)
